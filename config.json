{
  "name": "default_config",
  "n_gpu": 1,
  "preprocessing": {
    "sr": 22050
  },
  "arch": {
    "type": "HiFiGAN",
    "args": {
      "u_kernel_size": [16, 16, 4, 4],
      "res_kernel_size": [3, 7, 11],
      "dilation": [
        [[1, 1], [3, 1], [5, 1]],
        [[1, 1], [3, 1], [5, 1]],
        [[1, 1], [3, 1], [5, 1]]
      ], 
      "stride": [8, 8, 2, 2],
      "conv_channels": 512
    }
  },
  "data": {
    "train": {
      "batch_size": 1,
      "num_workers": 0,
      "datasets": [
        {
          "type": "LJspeechDataset",
          "args": {
            "part": "train",
            "max_audio_length": 8192,
            "limit": 1,
            "data_dir": "/kaggle/input/the-lj-speech-dataset/LJSpeech-1.1/wavs"
          }
        }
      ]
    }
  },
  "gen_optimizer": {
    "type": "AdamW",
    "args": {
      "lr": 3e-4,
      "betas": [0.8, 0.99],
      "weight_decay": 1e-2
    }
  },
  "desc_optimizer": {
    "type": "AdamW",
    "args": {
      "lr": 3e-4,
      "betas": [0.8, 0.99],
      "weight_decay": 1e-2
    }
  },
  "loss": {
    "type": "GANLoss",
    "args": {
      "mel_scale": 45, 
      "fm_scale": 2
    }
  },
  "gen_lr_scheduler": {
    "type": "ExponentialLR",
    "args": {
      "gamma": 0.999
    }
  },
  "desc_lr_scheduler": {
    "type": "ExponentialLR",
    "args": {
      "gamma": 0.999
    }
  },
  "trainer": {
    "epochs": 50,
    "save_dir": "saved/",
    "save_period": 2,
    "verbosity": 2,
    "monitor": "min train_loss",
    "early_stop": 100,
    "visualize": "wandb",
    "wandb_project": "nv_project",
    "len_epoch": 2,
    "grad_norm_clip": 10
  }
}
